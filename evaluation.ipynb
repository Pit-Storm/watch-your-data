{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Var init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN0 = 'vocabulary-embedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN1 = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlend=25 # 0 - if we dont want to use description at all\n",
    "maxlenh=25\n",
    "maxlen = maxlend + maxlenh\n",
    "rnn_size = 512 # must be same as 160330-word-gen\n",
    "rnn_layers = 3  # match FN1\n",
    "batch_norm=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_rnn_size = 40 if maxlend else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "seed=42\n",
    "p_W, p_U, p_dense, weight_decay = 0, 0, 0, 0\n",
    "optimizer = 'adam'\n",
    "LR = 1e-4\n",
    "batch_size=64\n",
    "nflips=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 30000 # orig was 30k\n",
    "nb_val_samples = 3000 # orig was 3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_unknown_words = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/%s.pkl'%FN0, 'rb') as fp:\n",
    "    embedding, idx2word, word2idx, glove_idx2idx = pickle.load(fp)\n",
    "vocab_size, embedding_size = embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = 0\n",
    "eos = 1\n",
    "idx2word[empty] = '_'\n",
    "idx2word[eos] = '~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_unknown_words):\n",
    "    idx2word[vocab_size-1-i] = '<%d>'%i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov0 = vocab_size-nb_unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(oov0, len(idx2word)):\n",
    "    idx2word[i] = idx2word[i]+'^'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "import random, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from tensorflow.python.keras.layers.wrappers import TimeDistributed\n",
    "from tensorflow.python.keras.layers.recurrent import LSTM\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from tensorflow.python.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed weight initialization\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = l2(weight_decay) if weight_decay else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size,\n",
    "                    input_length=maxlen,\n",
    "                    embeddings_regularizer=regularizer, weights=[embedding], mask_zero=True,\n",
    "                    name='embedding_1'))\n",
    "\n",
    "for i in range(rnn_layers):\n",
    "    lstm = LSTM(rnn_size, return_sequences=True, # batch_norm=batch_norm,\n",
    "                kernel_regularizer=regularizer, recurrent_regularizer=regularizer,\n",
    "                bias_regularizer=regularizer, dropout=p_W, recurrent_dropout=p_U,\n",
    "                name='lstm_%d'%(i+1)\n",
    "                  )\n",
    "    model.add(lstm)\n",
    "    model.add(Dropout(p_dense,name='dropout_%d'%(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers.core import Lambda\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "def simple_context(X, mask, n=activation_rnn_size, maxlend=maxlend, maxlenh=maxlenh):\n",
    "    desc, head = X[:,:maxlend,:], X[:,maxlend:,:]\n",
    "    head_activations, head_words = head[:,:,:n], head[:,:,n:]\n",
    "    desc_activations, desc_words = desc[:,:,:n], desc[:,:,n:]\n",
    "    \n",
    "    # RTFM http://deeplearning.net/software/theano/library/tensor/basic.html#theano.tensor.batched_tensordot\n",
    "    # activation for every head word and every desc word\n",
    "    activation_energies = K.batch_dot(head_activations, desc_activations, axes=(2,2))\n",
    "    # make sure we dont use description words that are masked out\n",
    "    activation_energies = activation_energies + -1e20*K.expand_dims(1.-K.cast(mask[:, :maxlend],'float32'),1)\n",
    "    \n",
    "    # for every head word compute weights for every desc word\n",
    "    activation_energies = K.reshape(activation_energies,(-1,maxlend))\n",
    "    activation_weights = K.softmax(activation_energies)\n",
    "    activation_weights = K.reshape(activation_weights,(-1,maxlenh,maxlend))\n",
    "\n",
    "    # for every head word compute weighted average of desc words\n",
    "    desc_avg_word = K.batch_dot(activation_weights, desc_words, axes=(2,1))\n",
    "    return K.concatenate((desc_avg_word, head_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation_rnn_size:\n",
    "    model.add(Lambda(simple_context,\n",
    "                     mask = lambda inputs, mask: mask[:,maxlend:],\n",
    "                     output_shape = lambda input_shape: (input_shape[0], maxlenh, 2*(rnn_size - activation_rnn_size)),\n",
    "                     name='simplecontext_1'))\n",
    "model.add(TimeDistributed(Dense(vocab_size,\n",
    "                                kernel_regularizer=regularizer, bias_regularizer=regularizer,\n",
    "                                name = 'timedistributed_1')))\n",
    "model.add(Activation('softmax', name='activation_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import Adam, RMSprop # usually I prefer Adam but article used rmsprop\n",
    "# opt = Adam(lr=LR)  # keep calm and reduce learning rate\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr,np.float32(LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           4000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 512)           1255424   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "simplecontext_1 (Lambda)     (None, 25, 944)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 25, 40000)         37800000  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 25, 40000)         0         \n",
      "=================================================================\n",
      "Total params: 47,253,824\n",
      "Trainable params: 47,253,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define required funs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpadd(x, maxlend=maxlend, eos=eos):\n",
    "    \"\"\"left (pre) pad a description to maxlend and then add eos.\n",
    "    The eos is the input to predicting the first word in the headline\n",
    "    \"\"\"\n",
    "    assert maxlend >= 0\n",
    "    if maxlend == 0:\n",
    "        return [eos]\n",
    "    n = len(x)\n",
    "    if n > maxlend:\n",
    "        x = x[-maxlend:]\n",
    "        n = maxlend\n",
    "    return [empty]*(maxlend-n) + x + [eos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variation to https://github.com/ryankiros/skip-thoughts/blob/master/decoding/search.py\n",
    "def beamsearch(predict, start=[empty]*maxlend + [eos],\n",
    "               k=1, maxsample=maxlen, use_unk=True, empty=empty, eos=eos, temperature=1.0):\n",
    "    \"\"\"return k samples (beams) and their NLL scores, each sample is a sequence of labels,\n",
    "    all samples starts with an `empty` label and end with `eos` or truncated to length of `maxsample`.\n",
    "    You need to supply `predict` which returns the label probability of each sample.\n",
    "    `use_unk` allow usage of `oov` (out-of-vocabulary) label in samples\n",
    "    \"\"\"\n",
    "    def sample(energy, n, temperature=temperature):\n",
    "        \"\"\"sample at most n elements according to their energy\"\"\"\n",
    "        n = min(n,len(energy))\n",
    "        prb = np.exp(-np.array(energy) / temperature )\n",
    "        res = []\n",
    "        for i in range(n):\n",
    "            z = np.sum(prb)\n",
    "            r = np.argmax(np.random.multinomial(1, prb/z, 1))\n",
    "            res.append(r)\n",
    "            prb[r] = 0. # make sure we select each element only once\n",
    "        return res\n",
    "\n",
    "    dead_k = 0 # samples that reached eos\n",
    "    dead_samples = []\n",
    "    dead_scores = []\n",
    "    live_k = 1 # samples that did not yet reached eos\n",
    "    live_samples = [list(start)]\n",
    "    live_scores = [0]\n",
    "\n",
    "    while live_k:\n",
    "        # for every possible live sample calc prob for every possible label \n",
    "        probs = predict(live_samples, empty=empty)\n",
    "\n",
    "        # total score for every sample is sum of -log of word prb\n",
    "        cand_scores = np.array(live_scores)[:,None] - np.log(probs)\n",
    "        cand_scores[:,empty] = 1e20\n",
    "        if not use_unk:\n",
    "            for i in range(nb_unknown_words):\n",
    "                cand_scores[:,vocab_size - 1 - i] = 1e20\n",
    "        live_scores = list(cand_scores.flatten())\n",
    "        \n",
    "\n",
    "        # find the best (lowest) scores we have from all possible dead samples and\n",
    "        # all live samples and all possible new words added\n",
    "        scores = dead_scores + live_scores\n",
    "        ranks = sample(scores, k)\n",
    "        n = len(dead_scores)\n",
    "        ranks_dead = [r for r in ranks if r < n]\n",
    "        ranks_live = [r - n for r in ranks if r >= n]\n",
    "        \n",
    "        dead_scores = [dead_scores[r] for r in ranks_dead]\n",
    "        dead_samples = [dead_samples[r] for r in ranks_dead]\n",
    "        \n",
    "        live_scores = [live_scores[r] for r in ranks_live]\n",
    "\n",
    "        # append the new words to their appropriate live sample\n",
    "        voc_size = probs.shape[1]\n",
    "        live_samples = [live_samples[r//voc_size]+[r%voc_size] for r in ranks_live]\n",
    "\n",
    "        # live samples that should be dead are...\n",
    "        # even if len(live_samples) == maxsample we dont want it dead because we want one\n",
    "        # last prediction out of it to reach a headline of maxlenh\n",
    "        zombie = [s[-1] == eos or len(s) > maxsample for s in live_samples]\n",
    "        \n",
    "        # add zombies to the dead\n",
    "        dead_samples += [s for s,z in zip(live_samples,zombie) if z]\n",
    "        dead_scores += [s for s,z in zip(live_scores,zombie) if z]\n",
    "        dead_k = len(dead_samples)\n",
    "        # remove zombies from the living \n",
    "        live_samples = [s for s,z in zip(live_samples,zombie) if not z]\n",
    "        live_scores = [s for s,z in zip(live_scores,zombie) if not z]\n",
    "        live_k = len(live_samples)\n",
    "\n",
    "    return dead_samples + live_samples, dead_scores + live_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_rnn_predict(samples, empty=empty, model=model, maxlen=maxlen):\n",
    "    \"\"\"for every sample, calculate probability for every possible label\n",
    "    you need to supply your RNN model and maxlen - the length of sequences it can handle\n",
    "    \"\"\"\n",
    "    sample_lengths = list(map(len, samples))\n",
    "    assert all(l > maxlend for l in sample_lengths)\n",
    "    assert all(l[maxlend] == eos for l in samples)\n",
    "    # pad from right (post) so the first maxlend will be description followed by headline\n",
    "    data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    probs = model.predict(data, verbose=0, batch_size=batch_size)\n",
    "    return np.array([prob[sample_length-maxlend-1] for prob, sample_length in list(zip(probs, sample_lengths))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_fold(xs):\n",
    "    \"\"\"convert list of word indexes that may contain words outside vocab_size to words inside.\n",
    "    If a word is outside, try first to use glove_idx2idx to find a similar word inside.\n",
    "    If none exist then replace all accurancies of the same unknown word with <0>, <1>, ...\n",
    "    \"\"\"\n",
    "    xs = [x if x < oov0 else glove_idx2idx.get(x,x) for x in xs]\n",
    "    # the more popular word is <0> and so on\n",
    "    outside = sorted([x for x in xs if x >= oov0])\n",
    "    # if there are more than nb_unknown_words oov words then put them all in nb_unknown_words-1\n",
    "    outside = dict((x,vocab_size-1-min(i, nb_unknown_words-1)) for i, x in enumerate(outside))\n",
    "    xs = [outside.get(x,x) for x in xs]\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_unfold(desc,xs):\n",
    "    # assume desc is the unfolded version of the start of xs\n",
    "    unfold = {}\n",
    "    for i, unfold_idx in enumerate(desc):\n",
    "        fold_idx = xs[i]\n",
    "        if fold_idx >= oov0:\n",
    "            unfold[fold_idx] = unfold_idx\n",
    "    return [unfold.get(x,x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import Levenshtein\n",
    "\n",
    "def gensamples(skips=2, k=10, batch_size=batch_size, short=True, temperature=1., use_unk=True):\n",
    "    result = {}\n",
    "    i = random.randint(0,len(X_test)-1)\n",
    "    result[\"HEAD\"] = [idx2word[w] for w in Y_test[i][:maxlenh]]\n",
    "    #print('HEAD:',' '.join(result[\"HEAD\"][w] for w in range(len(result[\"HEAD\"]))))\n",
    "    result[\"DESC\"] = [idx2word[w] for w in X_test[i][:maxlend]]\n",
    "    #print('DESC:',' '.join(result[\"DESC\"][w] for w in range(len(result[\"DESC\"]))))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    print(\"Generating Headline...\", end=\" \")\n",
    "    #print('HEADS:')\n",
    "    x = X_test[i]\n",
    "    samples = []\n",
    "    if maxlend == 0:\n",
    "        skips = [0]\n",
    "    else:\n",
    "        skips = range(min(maxlend,len(x)), max(maxlend,len(x)), abs(maxlend - len(x)) // skips + 1)\n",
    "    for s in skips:\n",
    "        start = lpadd(x[:s])\n",
    "        fold_start = vocab_fold(start)\n",
    "        sample, score = beamsearch(predict=keras_rnn_predict, start=fold_start, k=k, temperature=temperature, use_unk=use_unk)\n",
    "        assert all(s[maxlend] == eos for s in sample)\n",
    "        samples += [(s,start,scr) for s,scr in zip(sample,score)]\n",
    "\n",
    "    samples.sort(key=lambda x: x[-1])\n",
    "    codes = []\n",
    "    for sample, start, score in samples:\n",
    "        code = ''\n",
    "        words = []\n",
    "        sample = vocab_unfold(start, sample)[len(start):]\n",
    "        for w in sample:\n",
    "            if w == eos:\n",
    "                break\n",
    "            words.append(idx2word[w])\n",
    "            code += chr(w//(256*256)) + chr((w//256)%256) + chr(w%256)\n",
    "        #if short:\n",
    "            #distance = min([100] + [-Levenshtein.jaro(code,c) for c in codes])\n",
    "            #if distance > -0.6:\n",
    "                #print(score, ' '.join(words))\n",
    "                #print('%s (%.2f) %f'%(' '.join(words), score, distance))\n",
    "        #else:\n",
    "            #print(score, ' '.join(words))\n",
    "        codes.append(code)\n",
    "\n",
    "    result[\"HEADS\"] = words\n",
    "    result[\"CODES\"] = codes\n",
    "    print(\"Done!\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/%s.data.pkl'%FN0, 'rb') as fp:\n",
    "    X, Y = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170028, 170028, 3000, 3000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=nb_val_samples, random_state=seed)\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, Y\n",
    "del X_train, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate examples per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results load from File.\n"
     ]
    }
   ],
   "source": [
    "if vm:\n",
    "    res = []\n",
    "    batch_samples = nb_val_samples//batch_size\n",
    "else:\n",
    "    with open(\"data/gen.res.pkl\", \"rb\") as fp:\n",
    "        res = pickle.load(fp)\n",
    "    print(\"Results load from File.\")\n",
    "\n",
    "for ite in range(13):\n",
    "    if not vm:\n",
    "        break\n",
    "    res.append([])\n",
    "    # We need this if-elif statement because of the interruption during training\n",
    "    if ite < 3:\n",
    "        model.load_weights(\"data/train/01-it-{}.weights.hdf5\".format(ite))\n",
    "    elif ite >= 3:\n",
    "        model.load_weights(\"data/train/02-it-{}.weights.hdf5\".format(ite-3))\n",
    "    for ex in range(1,batch_samples+1):\n",
    "        print(\"{}. Iteration of {} -\".format(ite,12),end=\" \")\n",
    "        print(\"{}. of {} examples:\".format(ex,batch_samples))\n",
    "        res[ite].append(gensamples(skips=2, batch_size=batch_size, k=10, temperature=1.))\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vm:\n",
    "    with open(\"data/gen.res.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(res,fp)\n",
    "    print(\"Stored results to file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 1-gramm Corpus-BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_weights = [1.]\n",
    "score = []\n",
    "for ite in range(len(res)):\n",
    "    ref = []\n",
    "    cand = []\n",
    "    for ex in range(len(res[ite])):\n",
    "        ref.append(res[ite][ex][\"HEAD\"])\n",
    "        cand.append(res[ite][ex][\"HEADS\"])\n",
    "    score.append(corpus_bleu(ref,cand,weights=score_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot BLEU-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(score)\n",
    "plt.title('Model BLEU-Score')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do this in two parts, because of the interruption during training\n",
    "with open(\"data/train/01-it-2.history.pkl\", \"rb\") as fp:\n",
    "    history = [pickle.load(fp)]\n",
    "with open(\"data/train/02-it-9.history.pkl\", \"rb\") as fp:\n",
    "    history.append(pickle.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in history[1][\"loss\"]:\n",
    "    history[0][\"loss\"].append(val)\n",
    "for val in history[1][\"val_loss\"]:\n",
    "    history[0][\"val_loss\"].append(val) \n",
    "\n",
    "history = {\"loss\": history[0][\"loss\"],\n",
    "          \"val_loss\": history[0][\"val_loss\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Log-Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VfWd//HXJ3sICSEkgSxA2BQQTSK4VwWXFi2yVOvS2tpOV9u61HZanfbXxelMN1u1i12marXt2LEqijgujIorLmyJgsomSxYhAQIkgYQkn98f95LGyBKS3Jx7k/fz8bgP7j335OZ9FPLO+Z5zvsfcHREREYC4oAOIiEj0UCmIiEg7lYKIiLRTKYiISDuVgoiItFMpiIhIO5WCDDhmVmRmbmYJXVj3M2b2Yl/kOkyG6WZWEWQGGThUChLVzGyjmTWbWXan5SvDP9iLgkl2dOUiEitUChIL3gWuOPDCzI4HUoOLI9J/qRQkFvwF+HSH11cB93ZcwcyGmNm9ZlZjZpvM7LtmFhd+L97MbjGzWjPbAHz0IF97p5lVm1mlmf3IzOJ7EtjMks3sNjOrCj9uM7PkDu9/K/z9qszs8+E9jvFd/OxJZrbYzOrMbJWZze7w3oVmttrM9oS35Zvh5dlmtjD8NTvM7IUD/31EOtJfCokFrwAZ4R+G8cBlwF87rfNrYAgwFjibUIl8NvzeF4BZQCkwDbik09feA7QA48PrfBj4fA8zfwc4FSgBioGTge8CmNlM4AbgvPD3PLurH2pmicCjwFNALnAN8DczOza8yp3Al9w9HZgCPBNe/g2gAsgBhgP/BmiOG/kAlYLEigN7C+cDbwOVB97oUBQ3ufsed98I/AL4VHiVS4Hb3H2Lu+8Aftzha4cDFwDXu3uDu28DbgUu72HeTwI3u/s2d68Bftgpz93uvsrdG8PvddWpwGDgJ+7e7O7PAAv55/DafmCymWW4+053X95heR4w2t33u/sLronP5CBUChIr/gJ8AvgMnYaOgGwgCdjUYdkmoCD8PB/Y0um9A0YDiUB1eGilDvgDod/CeyL/IHnyD5Gn/bmZjTKz+gOPQ3zuFndv6/TZB7b1YuBCYJOZPWdmp4WX/xxYBzxlZhvM7Mbubpj0byoFiQnuvonQAecLgYc6vV1L6Dfh0R2WjeKfexPVwMhO7x2wBWgCst09M/zIcPfjehi56iB5qjrkKezwXns2d9/s7oMPPA7xuSM7HQ9o31Z3f93d5xAqtYeB+8PL97j7N9x9LHARcIOZndujLZR+SaUgseRzwDnu3tBxobu3Evrh9x9mlm5mowmN2R847nA/cK2ZFZrZUODGDl9bTWh8/hdmlmFmcWY2zsy6PM4PJJtZSodHHHAf8F0zywmfTvu9Tnk+Gz5GMij8Xle9CjQA3zKzRDObTuiH/N/NLMnMPmlmQ9x9P7AbaAUws1lmNt7MrMPy1qP4vjJAqBQkZrj7endfeoi3ryH0w3ID8CLw38Bd4ff+C3gSKAOW88E9jU8TGn5aDewEHiA0/t5V9cDeDo9zgB8BS4Fy4I3w9/1ReDseB34FPEtoSGdJ+HOajvSN3L0ZmE3oOEgtcAfwaXd/O7zKp4CNZrYb+DJwZXj5BOD/wlmXAHe4++Kj2EYZIEzHmkSCZWaTgDeBZHdvCTqPDGzaUxAJgJnNCw/3DAV+CjyqQpBooFIQCcaXgBpgPaGx/auDjSMSouEjERFppz0FERFpF/HZHcNXmy4FKt19Vqf3kgldiDQV2A5cFr4a9ZCys7O9qKgoMmFFRPqpZcuW1bp7zpHW64spf68D3gIyDvLe54Cd7j7ezC4ndMDtssN9WFFREUuXHuqsRBERORgz23TktSI8fGRmhYRmpPzTIVaZQ2gyMgidG35u+OIaEREJQKSPKdwGfAtoO8T7BYTnfQmfjrcLGNZ5JTP7opktNbOlNTU1kcoqIjLgRawUzGwWsM3dlx1utYMs+8DpUO7+R3ef5u7TcnKOOCQmIiLdFMk9hTOA2Wa2Efg7cI6ZdZ4Dv4LwZGDhWxoOAXZEMJOIiBxGxErB3W9y90J3LyI0N/0z7n5lp9UWELqLFoRufPKM5ngXEQlOn99w3MxuBpa6+wJCd4n6i5mtI7SH0NMbm4iISA/0SSmEZ2NcHH7+vQ7L9wEf74sMIiJyZAPmiuYVm3fy0yfePvKKIiID2IAphTcrd/G7xet5q3p30FFERKLWgCmFj56QT0Kc8fCKyiOvLCIyQA2YUshKS2L6sTk8vLKS1jad4CQicjADphQA5pUWsnV3E69s2B50FBGRqDSgSuHcSbmkJycwX0NIIiIHNaBKISUxnguOH8Hjb1Szt7k16DgiIlFnQJUChIaQGppbWfTW1qCjiIhEnQFXCqeMySJ/SArzl1cEHUVEJOoMuFKIizPmlBbw/Npaauubgo4jIhJVBlwpAMwrLaC1zVlYVhV0FBGRqDIgS+GY4elMzsvQWUgiIp0MyFIA+NiJBZRV7GJ9TX3QUUREosaALYWLivOJM3hEewsiIu0GbCkMz0jhjPHZzF9Zie7rIyISMmBLAUIHnLfs2MuyTTuDjiIiEhUGdCl85LgRpCbG64CziEjYgC6FtOQEPnLccBaWV9PUomkvREQGdCkAzC0tYNfe/Sx+pyboKCIigRvwpfCh8dlkD05m/nINIYmIDPhSSIiPY3ZxPs+8vY1djfuDjiMiEqgBXwoQOgupubWN/32zOugoIiKBUikAUwoyGJeTpiEkERnwVAqAmfGxEwt5beMOtuxoDDqOiEhgVAphs4vzAVigmVNFZABTKYSNzBrEyWOyeGh5haa9EJEBS6XQwbzSAtbXNPBm5e6go4iIBEKl0MGFU/JIio/joRW6VaeIDEwqhQ6GDErk3Em5PFpWRUtrW9BxRET6nEqhk7mlBdTWN/Piutqgo4iI9DmVQifTj81hSGqiZk4VkQFJpdBJckI8s07I48lV71Hf1BJ0HBGRPqVSOIh5pQXs29/GU6veCzqKiEifUikcxNTRQxmZlaohJBEZcFQKB2FmzCsp4KV1tWzdvS/oOCIifUalcAhzSwtoc1iwUtNeiMjAEbFSMLMUM3vNzMrMbJWZ/fAg64w2s6fNrNzMFptZYaTyHK2xOYMpHpmpISQRGVAiuafQBJzj7sVACTDTzE7ttM4twL3ufgJwM/DjCOY5avNK8lldvZt33tsTdBQRkT4RsVLwkPrwy8Two/NMc5OBp8PPnwXmRCpPd8wqzic+zrS3ICIDRkSPKZhZvJmtBLYBi9z91U6rlAEXh5/PA9LNbNhBPueLZrbUzJbW1NREMvL7ZA9O5uxjcnhkZSVtbZo5VUT6v4iWgru3unsJUAicbGZTOq3yTeBsM1sBnA1UAh+4Yszd/+ju09x9Wk5OTiQjf8Dc0gKqd+3j1Xd39On3FREJQp+cfeTudcBiYGan5VXu/jF3LwW+E162qy8yddX5k4YzODmB+Zo5VUQGgEiefZRjZpnh56nAecDbndbJNrMDGW4C7opUnu5KTYpn5pQRPP7Ge+zb3xp0HBGRiIrknkIe8KyZlQOvEzqmsNDMbjaz2eF1pgPvmNkaYDjwHxHM023zSgvY09TC029tCzqKiEhEJUTqg929HCg9yPLvdXj+APBApDL0llPHDmNERgrzV1Tw0RPygo4jIhIxuqK5C+LjjDkl+Sx+p4YdDc1BxxERiRiVQhfNLS2gpc1ZWK5pL0Sk/1IpdNGkvAwmjkjXhWwi0q+pFI7CvNICVmyuY2NtQ9BRREQiQqVwFGaX5GOG9hZEpN9SKRyFvCGpnD5uGA+vrMRd016ISP+jUjhKc0sK2LS9kRVb6oKOIiLS61QKR2nmlBEkJ8Qxf7mGkESk/1EpHKX0lEQ+fNwIFpZX0dzSFnQcEZFepVLohnml+exs3M9za/puGm8Rkb6gUuiGMyfkMCwtiYd1FpKI9DMqhW5IjI/jouJ8Fr21ld379gcdR0Sk16gUumluaQHNLW08/kZ10FFERHqNSqGbiguHMDY7TReyiUi/olLoJjNjbmkBr2zYQWXd3qDjiIj0CpVCD8wtKQDgkZXaWxCR/kGl0AOjhg1i2uihzF+uaS9EpH9QKfTQ3NIC1m6rZ1XV7qCjiIj0mEqhh2adkEdivOmaBRHpF1QKPZQ5KIkZx+bySFkVrW0aQhKR2KZS6AXzSguo2dPES+tqg44iItIjKoVeMGNiLhkpCRpCEpGYp1LoBSmJ8Xz0hDyeWPUejc0tQccREek2lUIvmVtSQGNzK0+t2hp0FBGRblMp9JKTirIoyEzVtBciEtNUCr0kLs6YW5rPC2trqNK0FyISoxKCDtCfzCst5HeL1/Ohnz7DMcPTKR01lNJRmZw4KpOx2YOJi7OgI4qIHJZKoReNzx3Mg1efznNrali+uY7Hyqu477XNAGSkJFAyaignjsqkdNRQSgozGTIoMeDEIiLvp1LoZaG9g6EAtLU5G2rrWb65jhWb61ixeSe3P72WA9Mkjc8dTOnITE4cHdqjmJCbTrz2JkQkQBZrE7lNmzbNly5dGnSMbqtvaqF8Sx3LN+9kxebQnzsbQ3dvG5ycQPHIIZSODJVE6aihZKUlBZxYRPoDM1vm7tOOtJ72FPrY4OQETh+fzenjswFwdzZtb2TFlp0s31THii07+d1z69unzCgaNojSDsNOE0ekkxCv8wNEJDK0pxCFGptbeKNiFyu21LF8006Wb66jtr4JgNTEeI4vHMInTxnFnPD9HEREjkR7CjFsUFICp4wdxiljhwGhvYnKur3hYxM7eWFtLTfcX8aorEHtxy9ERHqD9hRi0K69+7nw9hdIjDceu/ZM0pLV7SJyeF3dU9DgdAwakprILy4tZtOORn702FtBxxGRfkSlEKNOHTuML541lvte28yi1ZpvSUR6R8RKwcxSzOw1Myszs1Vm9sODrDPKzJ41sxVmVm5mF0YqT390w/nHMDkvgxsfLKdmT1PQcUSkH4jknkITcI67FwMlwEwzO7XTOt8F7nf3UuBy4I4I5ul3khPiuf3yEuqbWvj2g+XE2vEhEYk+ESsFD6kPv0wMPzr/1HIgI/x8CFAVqTz91YTh6dx4wUSeeXsbf3t1c9BxRCTGRfSYgpnFm9lKYBuwyN1f7bTKD4ArzawC+F/gmkN8zhfNbKmZLa2pqYlk5Jh01WlFnDkhmx89tpr1NfVH/gIRkUOIaCm4e6u7lwCFwMlmNqXTKlcAf3b3QuBC4C9m9oFM7v5Hd5/m7tNycnIiGTkmxcUZt3y8mJTEeL7+PyvZ39oWdCQRiVF9cvaRu9cBi4GZnd76HHB/eJ0lQAqQ3ReZ+pvhGSn85GPHU16xi189vTboOCISoyJ59lGOmWWGn6cC5wFvd1ptM3BueJ1JhEpB40PdNHNKHpdMLeS3z65j2aYdQccRkRgUyT2FPOBZMysHXid0TGGhmd1sZrPD63wD+IKZlQH3AZ9xnULTI9+/aDIFQ1O5/n9WUt/UEnQcEYkxmuaiH1q6cQeX/mEJF59YyM8/Xhx0HBGJAprmYgCbVpTFV6aP5x/LKnj8jeqg44hIDFEp9FPXnTeBEwqHcNP8N9i6e1/QcUQkRnSpFMxsnJklh59PN7NrDxxEluiUGB/HrZeVsG9/K9/8RxltbbE1TCgiwejqnsKDQKuZjQfuBMYA/x2xVNIrxuUM5jsfncwLa2u5d8nGoOOISAzoaim0uXsLMA+4zd2/TujsIolyV54yihnH5vDjx99m7dY9QccRkSjX1VLYb2ZXAFcBC8PLEiMTSXqTmfGzS4oZnJzAdX9fSXOLrnYWkUPrail8FjgN+A93f9fMxgB/jVws6U056cn85OITWF29m18uWhN0HBGJYl0qBXdf7e7Xuvt9ZjYUSHf3n0Q4m/Si8ycP54qTR/KH59fzyobtQccRkSjV1bOPFptZhpllAWXA3Wb2y8hGk9723Y9OZnTWIL5xfxm79+0POo6IRKGuDh8NcffdwMeAu919KqG5jCSGpCUncOtlJby3ex/ff2RV0HFEJAp1tRQSzCwPuJR/HmiWGFQ6aijXnDOe+SsqWVCmexqJyPt1tRRuBp4E1rv762Y2FtD8zDHqazPGUzIyk+/Of4Oqur1BxxGRKNLVA83/cPcT3P3q8OsN7n5xZKNJpCTEx3HbZSW0tLmudhaR9+nqgeZCM5tvZtvMbKuZPWhmhZEOJ5FTlJ3G92ZN5uX127nrpXeDjiMiUaKrw0d3AwuAfKAAeDS8TGLYZSeN5PzJw/nZE+/wVvXuoOOISBToainkuPvd7t4SfvwZ0M2SY5yZ8ZOPHU9GaiLX/30l+/a3Bh1JRALW1VKoNbMrzSw+/LgS0BVQ/cCwwcn8/JITeGfrHm558p2g44hIwLpaCv9C6HTU94Bq4BJCU19IPzBjYi6fOnU0f3rxXV5aVxt0HBEJUFfPPtrs7rPdPcfdc919LqEL2aSf+LcLJzE2J41v3F9GXWNz0HFEJCA9ufPaDb2WQgKXmhTP7ZeVUlvfxHcefpNYu3e3iPSOnpSC9VoKiQrHFw7h6+cfw2Pl1Ty8sjLoOCISgJ6Ugn6V7Ie+fPY4po0eyvceXsWWHY1BxxGRPnbYUjCzPWa2+yCPPYSuWZB+Jj7OuPWyEhy44f6V7G3WaaoiA8lhS8Hd09094yCPdHdP6KuQ0rdGZg3i3+cex+sbdzLr1y/wRsWuoCOJSB/pyfCR9GPzSgv56+dOoaGplXl3vMSvn15LS6tu5SnS36kU5JA+NCGbJ68/iwuOz+MXi9Zw6R+WsGl7Q9CxRCSCVApyWEMGJfLrK0q5/fIS1m2r54LbX+C+1zbrlFWRfkqlIF0yp6SAJ64/i5KRmdz00Bt84d6l1OxpCjqWiPQylYJ0WX5mKn/93Cn8v1mTeX5tLTNve55Fq7cGHUtEepFKQY5KXJzxuQ+NYeE1H2J4RgpfuHcp336gnPqmlqCjiUgvUClItxwzPJ2Hv3oGX5k+jvuXbeHC219g2aYdQccSkR5SKUi3JSXE8a2ZE7n/S6fR5s7Hf7+Enz/5Ns0tOnVVJFapFKTHTirK4vHrzuSSqYX89tn1zLvjJdZu3RN0LBHpBpWC9Ir0lER+dkkxv79yKtW79jHr1y9y90vv0tamU1dFYolKQXrVzCkjeOL6MzljfDY/fHQ1n77rNap37Q06loh0kUpBel1uegp3XjWN/5x3PMs27eQjtz7Po2VVQccSkS6IWCmYWYqZvWZmZWa2ysx+eJB1bjWzleHHGjOri1Qe6VtmxidOGcX/XncmY3MGc819K7ju7yvY1bg/6GgichiR3FNoAs5x92KgBJhpZqd2XMHdv+7uJe5eAvwaeCiCeSQAY7LTeODLp3HD+cewsLyambc/r/tAi0SxiJWCh9SHXyaGH4c76ngFcF+k8khwEuLjuPbcCTx09emkJsbzyT+9yr8vXM2+/bpXg0i0iegxBTOLN7OVwDZgkbu/eoj1RgNjgGcO8f4XzWypmS2tqamJXGCJqOKRmTx27Zl8+rTR3Pniu8z+zYusqtK9GkSiSURLwd1bw0NDhcDJZjblEKteDjzg7gf91dHd/+ju09x9Wk5OTqTiSh9ITYrn5jlT+PNnT6KucT9zf/sSv3zqHRqbNU2GSDTok7OP3L0OWAzMPMQql6OhowFl+rG5PHn9WVx4fB6/emYd5/7iORaUVWlKbpGARfLsoxwzyww/TwXOA94+yHrHAkOBJZHKItFpaFoSt19eyj++fBpZaUlce98KLv3DEt6s1JCSSFAiuaeQBzxrZuXA64SOKSw0s5vNbHaH9a4A/u76FXHAOqkoiwVf+xA//tjxrK9p4KLfvMhND5WzvV73axDpaxZrP4unTZvmS5cuDTqGRMiuvfv51dNruefljaQmxXPduRO46vQiEuN1naVIT5jZMnefdqT19C9NosqQ1ET+36zJPHH9mZSOGsqPHnuLmbc9z3NrdNaZSF9QKUhUGp+bzj2fPYk7r5pGa5tz1V2v8fl7XmdjbUPQ0UT6NZWCRC0z49xJw3ny62dx4wUTWbJ+O+ff+hw/fvwt3elNJEJUChL1khPi+fLZ43j2m9OZU1LAH57bwIxbFvPAsgpNzS3Sy1QKEjNyM1K45ePFPPzVMyjITOWb/yhj3u9eZsXmnUFHE+k3VAoSc0pGZvLQ1afzi48XU1W3l3l3vMwN969k2+59QUcTiXkqBYlJcXHGxVMLefab07l6+jgWllUz45bF/G7xeppaNNGeSHepFCSmDU5O4NszJ/LU18/itHHZ/PSJt/nwrc+zaPVWTZkh0g0qBekXirLT+NNV07j3X04mMT6OL9y7lE/f9Rrrtu0JOppITFEpSL9y1jE5PH7dmXxv1mRWbqnjI7e9wA8fXcWuvbrjm0hXaJoL6be21zfxi0VruO+1zaQnJ/CZ04v4zBljyEpLCjqaSJ/r6jQXKgXp91ZV7eJXT6/lyVVbSU2M5xOnjOILZ45lxJCUoKOJ9BmVgkgna7bu4feL1/NIWRXxZlw8tYAvnTWOouy0oKOJRJxKQeQQtuxo5A/Pr+f+pRW0tLZxUXE+V08fx8QRGUFHE4kYlYLIEWzbvY87X3yXv76yiYbmVs6bNJyvzBjHiaOGBh1NpNepFES6qK6xmXte3sTdL79LXeN+Th83jK/OGM/p44ZhZkHHE+kVKgWRo9TQ1MJ9r23mv17YwNbdTRSPzOSr08dx3qThxMWpHCS2qRREuqmppZUHl1Xy++fWs3lHI8cMH8xXpo9n1gl5JOgOcBKjVAoiPdTS2sZjb1Rzx7PreWfrHkZmpfLls8dx8YmFpCTGBx1P5KioFER6SVub88zb2/jNs+tYuaWO3PRkvnDmWD5xyijSkhOCjifSJSoFkV7m7izZsJ07nl3Pi+tqGZKayGfPKOIzpxeROUhXSUt0UymIRNDKLXXc8ew6nlq9lUFJ8Vx56mg+/6Ex5GboKmmJTioFkT7wznt7+P1z61kQvkp6xsQc5pYUMGNiro47SFRRKYj0oc3bG7lnyUYWlFVRs6eJ9JQELpySx9zSAk4Zk6VTWiVwKgWRALS0trFkw3bmr6jkyTffo6G5lbwhKcwuyWduSQGT8jSVhgRDpSASsL3NrSx6ayuPrKjkuTU1tLQ5E0ekM6ekgDkl+eRnpgYdUQYQlYJIFNnR0Mxj5VXMX1HJ8s11mMHJRVnMKy3gguPzGJKaGHRE6edUCiJRatP2Bh5ZWcXDKyrZUNtAUnwc50zMZW5pPjMm5pKcoAPU0vtUCiJRzt15o3IXD6+oYkFZFbX1TWSkJHDh8aED1CcX6QC19B6VgkgMaWlt46X123lkRSVPrHqPxuZW8oekMLukgLml+brXg/SYSkEkRjU2t7Bo9VYeXlHJ82traQ0foJ5bWsDsYh2glu5RKYj0A7X1TTxWXs3DKytZET5APSY7jXE5g8OPNMblDmZc9mCGDNLBajk0lYJIP7OxtoGF5VW8UbmLDTUNbNzewP7Wf/77zR6cxNiDlEXB0FTidWxiwOtqKWiKR5EYUZSdxtfOmdD+uqW1jS0797J+Wz0bautZv62B9TX1PPFmNTsb97evl5QQx9j2vYtQWYzNHszYnDTN8iofoL8RIjEqIT6OMdlpjMlOA4a/770dDc1sqKlnfU0962saWL+tntXVu3n8zWraOgwO5A1JaS+L9r2M3DRGZKToVqQDlEpBpB/KSksiKy2LaUVZ71ve1NLK5u2N/yyL8J8PLa9kT1PL+77+gikjmF2cz0k6NXZAiVgpmFkK8DyQHP4+D7j79w+y3qXADwAHytz9E5HKJDLQJSfEM2F4OhOGp79vubtTU9/UPgT1yobtPLi8gr+9upm8ISnMOiGP2cUFTCnI0B5EPxexA80W+puT5u71ZpYIvAhc5+6vdFhnAnA/cI677zSzXHffdrjP1YFmkb7R0NTC/721lUfLqnhuTQ37W50x2WlcVJzP7OI8xuemH/lDJGpE1dlHZjaIUClc7e6vdlj+M2CNu/+pq5+lUhDpe3WNzTzx5nssKKtiyYbtuMOkvAxmF+dzUXEehUMHBR1RjiAqSsHM4oFlwHjgt+7+7U7vPwysAc4A4oEfuPsTB/mcLwJfBBg1atTUTZs2RSyziBzett37WFhezaPlVazYXAfA1NFDmV2cz4XH55GTnhxwQjmYqCiFDmEygfnANe7+ZoflC4H9wKVAIfACMMXd6w71WdpTEIkeW3Y0sqCsikfLqnj7vT3EGZw+LpvZxfl8ZMoIzf4aRaKqFADM7PtAg7vf0mHZ74FX3P3P4ddPAze6++uH+hyVgkh0WrN1DwtWhib327yjkaT4OM4+NoeLivM5b1Iug5J0smOQAi8FM8sB9rt7nZmlAk8BP3X3hR3WmQlc4e5XmVk2sAIocffth/pclYJIdHN3yit2saCsioXlVWzd3cSgpHjOmzSc2cX5nHVMDkkJcUHHHHCi4YrmPOCe8HGFOOB+d19oZjcDS919AfAk8GEzWw20Av96uEIQkehnZhSPzKR4ZCb/duEkXnt3BwvKqnj8zWoWlFWRkZLABVPyuKg4n+MLh2iIKcpo7iMR6RPNLW28tK6WBWVVPLUqdP9qgOzByYzNSQtdVR2efmNszmBGDk0lIV57FL0lGvYURETaJSXEMWNiLjMm5rK3uZWX19eydls9G2rq2VDTwJOrtrKjYUv7+onxxqisQYzNCRXFuA6FkZWWFOCW9G8qBRHpc6lJ8Zw7aTjnTnr/nE11jc2sr2kIFUVtQ3thPPdODc2tbe3rZQ5KZGx2WnthjM0Ozd80eliajlf0kEpBRKJG5qAkpo5OYurooe9b3tLaRmXdXjZ0mK9pQ009z62p4YFlFe3rxRn/3LsIl8bk/AyOy88gUUNRXaJSEJGolxAfx+hhoT2BGRNz3/fe7n37ebemgQ21ob2KA8Xx0rpamlpCexepifGUjsrkpKIsTirKonRUpqYNPwT9VxGRmJaRkth+tlNHbW1OZd1eyit28frGHby+cQe/fmYtbQ7xccZx+RlMG53FyWOGMnV0lq7EDtPZRyIyYOzZt5/lm+tYunEHr727g5Vb6tr3JsZmpzGtaGjq9VhbAAAHhklEQVT73sToYYP61YywgV+8FikqBRHpLc0tbbxRuYul4T2J1zfuZNfe0F3rctKTOaloaHhvIouJI9Jj+hRZlYKIyFFqa3PW1dSHCuLdUElU1u0FYHBywvuOS5SMzCQ1KT7gxF2nUhAR6QVVdXt5feMOlm7cyesbd/DO1j24h66jmFIwhJOKsjht7DA+NCE7qs9wUimIiETArsb9LNsc2ot4/d0dlFfsorm1jWFpScwpKeCSqYVMzs8IOuYHqBRERPrAvv2tvLSulgeXV/B/q7fR3NrG5LwMLplayJySfIYNjo6zmlQKIiJ9bGdDM4+WV/HAsgrKK3aREGfMmJjLJVMLmXFsbqBXW6sUREQC9M57e3hweQUPLa+ktr6JrLQk5pTkc8nUQo7LH9LneVQKIiJRoKW1jRfW1vLAsgoWrd5Kc2sbkzoML2X30fCSSkFEJMrUNTbzaFloeKmsw/DSxScWcs7EyA4vqRRERKLYmq17eHBZBQ+tqKRmTxNDByW2n710XH5Gr19NrVIQEYkBBxtemjginUumFjK3tKDXhpdUCiIiMaausZlHy6tDw0tb6kiIM6Yfm8MlUws5Z+LwHg0vqRRERGLY2q17eGB5BfOXV7ItPLz0g9nHMaekoFufp9txiojEsAnD07npgkn864eP5YV1tTy4rIKCzNSIf1+VgohIFEuIj2PGsbnMODb3yCv3guidvUlERPqcSkFERNqpFEREpJ1KQURE2qkURESknUpBRETaqRRERKSdSkFERNrF3DQXZlYDbOrml2cDtb0YJ0jalujTX7YDtC3RqifbMtrdc460UsyVQk+Y2dKuzP0RC7Qt0ae/bAdoW6JVX2yLho9ERKSdSkFERNoNtFL4Y9ABepG2Jfr0l+0AbUu0ivi2DKhjCiIicngDbU9BREQOQ6UgIiLtBkwpmNlMM3vHzNaZ2Y1B5+kuMxtpZs+a2VtmtsrMrgs6U0+YWbyZrTCzhUFn6QkzyzSzB8zs7fD/m9OCztRdZvb18N+tN83sPjNLCTpTV5nZXWa2zcze7LAsy8wWmdna8J9Dg8zYFYfYjp+H/36Vm9l8M8uMxPceEKVgZvHAb4ELgMnAFWY2OdhU3dYCfMPdJwGnAl+N4W0BuA54K+gQveB24Al3nwgUE6PbZGYFwLXANHefAsQDlweb6qj8GZjZadmNwNPuPgF4Ovw62v2ZD27HImCKu58ArAFuisQ3HhClAJwMrHP3De7eDPwdmBNwpm5x92p3Xx5+vofQD5/u3ck7YGZWCHwU+FPQWXrCzDKAs4A7Ady92d3rgk3VIwlAqpklAIOAqoDzdJm7Pw/s6LR4DnBP+Pk9wNw+DdUNB9sOd3/K3VvCL18BCiPxvQdKKRQAWzq8riBGf5B2ZGZFQCnwarBJuu024FtAW9BBemgsUAPcHR4K+5OZpQUdqjvcvRK4BdgMVAO73P2pYFP12HB3r4bQL1VA39zsOLL+BXg8Eh88UErBDrIsps/FNbPBwIPA9e6+O+g8R8vMZgHb3H1Z0Fl6QQJwIvA7dy8FGoiNIYoPCI+3zwHGAPlAmpldGWwq6cjMvkNoGPlvkfj8gVIKFcDIDq8LiaFd4s7MLJFQIfzN3R8KOk83nQHMNrONhIbzzjGzvwYbqdsqgAp3P7DH9gChkohF5wHvunuNu+8HHgJODzhTT201szyA8J/bAs7TbWZ2FTAL+KRH6CKzgVIKrwMTzGyMmSUROnC2IOBM3WJmRmjs+i13/2XQebrL3W9y90J3LyL0/+MZd4/J30jd/T1gi5kdG150LrA6wEg9sRk41cwGhf+unUuMHjTvYAFwVfj5VcAjAWbpNjObCXwbmO3ujZH6PgOiFMIHZ74GPEnoL/j97r4q2FTddgbwKUK/Wa8MPy4MOpRwDfA3MysHSoD/DDhPt4T3dh4AlgNvEPoZETPTRJjZfcAS4FgzqzCzzwE/Ac43s7XA+eHXUe0Q2/EbIB1YFP53//uIfG9NcyEiIgcMiD0FERHpGpWCiIi0UymIiEg7lYKIiLRTKYiISDuVgkgnZtba4XTflb05q66ZFXWc+VIk2iQEHUAkCu1195KgQ4gEQXsKIl1kZhvN7Kdm9lr4MT68fLSZPR2e5/5pMxsVXj48PO99WfhxYLqIeDP7r/A9C54ys9TANkqkE5WCyAeldho+uqzDe7vd/WRCV5feFl72G+De8Dz3fwN+FV7+K+A5dy8mNBfSgavoJwC/dffjgDrg4ghvj0iX6YpmkU7MrN7dBx9k+UbgHHffEJ6U8D13H2ZmtUCeu+8PL69292wzqwEK3b2pw2cUAYvCN3zBzL4NJLr7jyK/ZSJHpj0FkaPjh3h+qHUOpqnD81Z0bE+iiEpB5Ohc1uHPJeHnL/PPW1Z+Engx/Pxp4Gpovxd1Rl+FFOku/YYi8kGpZrayw+sn3P3AaanJZvYqoV+orggvuxa4y8z+ldAd2D4bXn4d8MfwDJethAqiOuLpRXpAxxREuih8TGGau9cGnUUkUjR8JCIi7bSnICIi7bSnICIi7VQKIiLSTqUgIiLtVAoiItJOpSAiIu3+P1tS276pfg0VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.title('Model Log-loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
