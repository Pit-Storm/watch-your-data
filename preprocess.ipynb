{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_pickle(\"data/data_raw.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:  19076\n",
      "Rows left: 185059\n"
     ]
    }
   ],
   "source": [
    "before = df_news.shape[0]\n",
    "\n",
    "to_drop = [\"\",\"[]\"]\n",
    "for col in df_news.columns:\n",
    "    if col != \"ID\":\n",
    "        for item in to_drop:\n",
    "            df_news = df_news[df_news[col] != item]\n",
    "        df_news = df_news[df_news[col].notnull()]\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping only first ten sentences of \"Content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_10(row):\n",
    "    \"\"\"Only keep first 10 sentences of Content\n",
    "    *args: pandas row object\n",
    "    return: string\n",
    "    \"\"\"\n",
    "    return reduce(lambda i,j: i + j, re.split(r'(\\.\\s)', row ,10)[:20])\n",
    "\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(keep_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "# Only when first using nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news[\"Headline\"] = df_news[\"Headline\"].str.lower()\n",
    "df_news[\"Content\"] = df_news[\"Content\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline done. Took  0 minutes.\n",
      "Done. Took  7 minutes.\n"
     ]
    }
   ],
   "source": [
    "tokenize_start = time.time()\n",
    "df_news[\"Headline\"] = df_news[\"Headline\"].apply(nltk.word_tokenize)\n",
    "tokenize_end = time.time()\n",
    "print(\"Headline done. Took {0:2.0f} minutes.\".format((tokenize_end - tokenize_start)/60))\n",
    "\n",
    "tokenize_start = time.time()\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(nltk.word_tokenize)\n",
    "tokenize_end = time.time()\n",
    "print(\"Done. Took {0:2.0f} minutes.\".format((tokenize_end - tokenize_start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_news.to_pickle(\"data/data_preprocessed.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_pickle(\"data/data_preprocessed.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Headlines > 25 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headline_gt_25(item):\n",
    "    \"\"\"\n",
    "    rows with more than 25 tokens in headline\n",
    "    \n",
    "    *args: row\n",
    "    return: row\n",
    "    \"\"\"\n",
    "    if len(item) > 25: return True\n",
    "    else: return False\n",
    "\n",
    "df_news = df_news[df_news[\"Headline\"].apply(headline_gt_25) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortening Content down to <= 50 tokens\n",
    "\n",
    "# TODO\n",
    "Check iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_content(item):\n",
    "    \"\"\"\n",
    "    Shortening content down to <= 50 tokens be aware of sentences.\n",
    "    \n",
    "    *args: content item list\n",
    "    return: shortend content item list\n",
    "    \"\"\"\n",
    "    if len(item) > 50:\n",
    "        last_point = 0\n",
    "        for i in range(len(item)):\n",
    "            if item[i] == '.':\n",
    "                last_point = i\n",
    "            if i > 50:\n",
    "                return item[:last_point]\n",
    "    else:\n",
    "        return item\n",
    "\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(short_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[agent, cooper, in, twin, peaks, is, the, audi...</td>\n",
       "      <td>[and, never, more, so, than, in, showtime, ’, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[ai, ,, the, humanity, !]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[the, viral, machine]</td>\n",
       "      <td>[super, deluxe, built, a, weird, internet, emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[how, anker, is, beating, apple, and, samsung,...</td>\n",
       "      <td>[steven, yang, quit, his, job, at, google, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[tour, black, panther, ’, s, reimagined, homel...</td>\n",
       "      <td>[ahead, of, black, panther, ’, s, 2018, theatr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Headline  \\\n",
       "0   1  [agent, cooper, in, twin, peaks, is, the, audi...   \n",
       "1   2                          [ai, ,, the, humanity, !]   \n",
       "2   3                              [the, viral, machine]   \n",
       "3   4  [how, anker, is, beating, apple, and, samsung,...   \n",
       "4   5  [tour, black, panther, ’, s, reimagined, homel...   \n",
       "\n",
       "                                             Content  \n",
       "0  [and, never, more, so, than, in, showtime, ’, ...  \n",
       "1                                                 []  \n",
       "2  [super, deluxe, built, a, weird, internet, emp...  \n",
       "3  [steven, yang, quit, his, job, at, google, in,...  \n",
       "4  [ahead, of, black, panther, ’, s, 2018, theatr...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
