{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_pickle(\"data/data_raw.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:  19076\n",
      "Rows left: 185059\n"
     ]
    }
   ],
   "source": [
    "before = df_news.shape[0]\n",
    "\n",
    "to_drop = [\"\",\"[]\"]\n",
    "for col in df_news.columns:\n",
    "    if col != \"ID\":\n",
    "        for item in to_drop:\n",
    "            df_news = df_news[df_news[col] != item]\n",
    "        df_news = df_news[df_news[col].notnull()]\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing interpunction misstakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_interpunction(item):\n",
    "    \"\"\"\n",
    "    Inserting space when missing after sentence ending.\n",
    "    *args: item string\n",
    "    return: fixed item string\n",
    "    \"\"\"\n",
    "    match = re.search(r\"[\\w\\d][\\.\\!\\?][\\w\\d]\",item)\n",
    "    if match:\n",
    "        item = item[:match.start()+2] + str(\" \") + item[match.end()-1:]\n",
    "        return fix_interpunction(item)\n",
    "    else:\n",
    "        return item\n",
    "\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(fix_interpunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping only first ten sentences of \"Content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_10(row):\n",
    "    \"\"\"Only keep first 10 sentences of Content\n",
    "    *args: pandas row object\n",
    "    return: string\n",
    "    \"\"\"\n",
    "    return reduce(lambda i,j: i + j, re.split(r'([\\.\\!\\?]\\s)', row ,10)[:20])\n",
    "\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(keep_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace lot of spaces with only one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_spaces(string):\n",
    "    \"\"\"\n",
    "    checking if there are mor then 2 concatenated spaces and replace it with one.\n",
    "    *args: string\n",
    "    return: string\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\s{2,}\",\" \",string)\n",
    "\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(replace_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting not expected chars from content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_format_1(string):\n",
    "    \"\"\"\n",
    "    replace not expacted chars with space\n",
    "    *args: content string\n",
    "    return: string\n",
    "    \"\"\"\n",
    "    return re.sub(r\"[\\\\\\,\\'\\s]{3,}(?=[A-Z]|\\\")\",\" \",string)\n",
    "\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(bad_format_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_format_2(string):\n",
    "    \"\"\"\n",
    "    deleting all backslashes\n",
    "    *args: content-string\n",
    "    return: string\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\\\{1,}\",\"\",string)\n",
    "\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(bad_format_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows the content has bunch of non letter chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:    294\n",
      "Rows left: 184765\n"
     ]
    }
   ],
   "source": [
    "def non_char_bunch(string):\n",
    "    \"\"\"\n",
    "    checking if string has any bunch of non letter chars in concatenation\n",
    "    \n",
    "    *args: string\n",
    "    return: Bool\n",
    "    \"\"\"\n",
    "    if re.search(r\"(\\\\{1,}\\'{1,})|(\\\\{2,})|(\\{{1,})\",string): return True\n",
    "    else: return False\n",
    "\n",
    "before = df_news.shape[0]\n",
    "\n",
    "df_news = df_news[df_news[\"Content\"].apply(non_char_bunch)==False]\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows the headline occurs in Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:    839\n",
      "Rows left: 183926\n"
     ]
    }
   ],
   "source": [
    "def headline_in_content(row):\n",
    "    is_in = row[\"Content\"].find(row[\"Headline\"])\n",
    "    if is_in == -1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "before = df_news.shape[0]\n",
    "\n",
    "df_news = df_news[df_news.apply(headline_in_content, axis=1) == False]\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:   7626\n",
      "Rows left: 176300\n"
     ]
    }
   ],
   "source": [
    "before = df_news.shape[0]\n",
    "\n",
    "df_news = df_news.drop_duplicates(\"Headline\")\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows the content is snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:    103\n",
      "Rows left: 176197\n"
     ]
    }
   ],
   "source": [
    "def is_snippet(content):\n",
    "    if content.find(\"... Continue\") != -1: return True\n",
    "    else: return False\n",
    "\n",
    "before = df_news.shape[0]\n",
    "\n",
    "df_news = df_news[df_news[\"Content\"].apply(is_snippet)==False]\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import time\n",
    "# Only when first using nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news[\"Headline\"] = df_news[\"Headline\"].str.lower()\n",
    "df_news[\"Content\"] = df_news[\"Content\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline done. Took 0.3 minutes.\n",
      "Content Done. Took 4.6 minutes.\n"
     ]
    }
   ],
   "source": [
    "tokenize_start = time.time()\n",
    "df_news[\"Headline\"] = df_news[\"Headline\"].apply(nltk.word_tokenize)\n",
    "tokenize_end = time.time()\n",
    "print(\"Headline done. Took {0:2.1f} minutes.\".format((tokenize_end - tokenize_start)/60))\n",
    "\n",
    "tokenize_start = time.time()\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(nltk.word_tokenize)\n",
    "tokenize_end = time.time()\n",
    "print(\"Content Done. Took {0:2.1f} minutes.\".format((tokenize_end - tokenize_start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows the headline is > 25 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:    588\n",
      "Rows left: 175609\n"
     ]
    }
   ],
   "source": [
    "def headline_gt_25(item):\n",
    "    \"\"\"\n",
    "    rows with more than 25 tokens in headline\n",
    "    \n",
    "    *args: row\n",
    "    return: row\n",
    "    \"\"\"\n",
    "    if len(item) > 25: return True\n",
    "    else: return False\n",
    "\n",
    "before = df_news.shape[0]\n",
    "\n",
    "df_news = df_news[df_news[\"Headline\"].apply(headline_gt_25) == False]\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows the content is shorter then 25 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:    693\n",
      "Rows left: 174916\n"
     ]
    }
   ],
   "source": [
    "before = df_news.shape[0]\n",
    "df_news = df_news[df_news[\"Content\"].apply(lambda x: len(x)) > 25]\n",
    "after = df_news.shape[0]\n",
    "\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows the > 4 last tokens are non character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:   2238\n",
      "Rows left: 172678\n"
     ]
    }
   ],
   "source": [
    "def bad_format(list):\n",
    "    \"\"\"\n",
    "    giving true if last 4 list-items having non letters\n",
    "    *args: item-string\n",
    "    return: Bool\n",
    "    \"\"\"\n",
    "    chars = []\n",
    "    for idx in range(len(list[-10:])):\n",
    "        idx = idx*(-1)-1\n",
    "        if re.match(r\"\\W\",list[idx]):\n",
    "            chars.append(idx)\n",
    "            if len(chars) > 4:\n",
    "                return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "before = df_news.shape[0]\n",
    "df_news = df_news[df_news[\"Content\"].apply(bad_format) == False]\n",
    "after = df_news.shape[0]\n",
    "\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.to_pickle(\"data/data_preprocessed.pickle\")\n",
    "\n",
    "#df_news = pd.read_pickle(\"data/data_preprocessed.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortening Content down to last sentence having 50th token\n",
    "\n",
    "## TODO\n",
    "Producing None. ID = 8246, 8583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_content(item):\n",
    "    \"\"\"\n",
    "    Shortening content down to <= 50 tokens be aware of sentences.\n",
    "    \n",
    "    *args: content item list\n",
    "    return: shortend content item list\n",
    "    \"\"\"\n",
    "    if len(item) > 50:\n",
    "        endings = []\n",
    "        for i in range(len(item)):\n",
    "            result = re.search(r\"(\\.)|(\\!)|(\\?)|(\\.\\.\\.)\",item[i])\n",
    "            if result:\n",
    "                endings.append(i)\n",
    "            elif endings:\n",
    "                if endings[-1] > 49:\n",
    "                    return item[:endings[-1]+1]\n",
    "    else:\n",
    "        return item\n",
    "\n",
    "df_short = df_news[\"Content\"].apply(shorten_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3880      None\n",
       "4277      None\n",
       "4351      None\n",
       "4720      None\n",
       "5427      None\n",
       "6295      None\n",
       "7192      None\n",
       "7222      None\n",
       "9275      None\n",
       "10719     None\n",
       "13212     None\n",
       "14583     None\n",
       "18427     None\n",
       "18970     None\n",
       "19163     None\n",
       "20530     None\n",
       "21320     None\n",
       "21749     None\n",
       "22034     None\n",
       "22327     None\n",
       "22472     None\n",
       "23090     None\n",
       "23391     None\n",
       "23802     None\n",
       "24213     None\n",
       "24322     None\n",
       "24473     None\n",
       "27005     None\n",
       "27195     None\n",
       "27367     None\n",
       "          ... \n",
       "176813    None\n",
       "177919    None\n",
       "178418    None\n",
       "180106    None\n",
       "180622    None\n",
       "182536    None\n",
       "182812    None\n",
       "182957    None\n",
       "183765    None\n",
       "185268    None\n",
       "188164    None\n",
       "190044    None\n",
       "190375    None\n",
       "190919    None\n",
       "191228    None\n",
       "191365    None\n",
       "192003    None\n",
       "195777    None\n",
       "196251    None\n",
       "196690    None\n",
       "196825    None\n",
       "197399    None\n",
       "197572    None\n",
       "197596    None\n",
       "200866    None\n",
       "201855    None\n",
       "202505    None\n",
       "203467    None\n",
       "203646    None\n",
       "204024    None\n",
       "Name: Content, Length: 281, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short[df_short.isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.search(r\"(\\.)|(\\!)|(\\?)|(\\.\\.\\.)\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " '\\\\n\\\\ntens',\n",
       " 'of',\n",
       " 'thousands',\n",
       " 'of',\n",
       " 'migrants',\n",
       " 'fleeing',\n",
       " 'war',\n",
       " 'and',\n",
       " 'poverty',\n",
       " 'are',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'reach',\n",
       " 'safety',\n",
       " 'in',\n",
       " 'europe',\n",
       " '.',\n",
       " 'this',\n",
       " 'summer',\n",
       " \"'s\",\n",
       " 'unprecedented',\n",
       " 'exodus',\n",
       " 'from',\n",
       " 'syria',\n",
       " ',',\n",
       " 'afghanistan',\n",
       " ',',\n",
       " 'eritrea',\n",
       " 'and',\n",
       " 'other',\n",
       " 'nations',\n",
       " 'in',\n",
       " 'turmoil',\n",
       " 'has',\n",
       " 'inundated',\n",
       " 'southern',\n",
       " 'europe',\n",
       " 'and',\n",
       " 'exhausted',\n",
       " 'the',\n",
       " 'generosity',\n",
       " 'of',\n",
       " 'countries',\n",
       " 'suffering',\n",
       " 'their',\n",
       " 'own',\n",
       " 'economic',\n",
       " 'woes',\n",
       " '.',\n",
       " '``',\n",
       " ',',\n",
       " \"'migrants\",\n",
       " 'have',\n",
       " 'flooded',\n",
       " 'into',\n",
       " 'slovenia',\n",
       " 'since',\n",
       " 'hungary',\n",
       " 'closed',\n",
       " 'its',\n",
       " 'border',\n",
       " 'with',\n",
       " 'serbia',\n",
       " 'to',\n",
       " 'people',\n",
       " 'making',\n",
       " 'arduous',\n",
       " 'treks',\n",
       " 'across',\n",
       " 'europe',\n",
       " 'in',\n",
       " 'september',\n",
       " 'and',\n",
       " 'clamped',\n",
       " 'down',\n",
       " 'on',\n",
       " 'its',\n",
       " 'border',\n",
       " 'with\\\\xa0',\n",
       " 'croatia',\n",
       " 'on',\n",
       " 'saturday.\\\\xa0',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'since\",\n",
       " 'then',\n",
       " ',',\n",
       " '21,500',\n",
       " 'people',\n",
       " 'have',\n",
       " 'entered',\n",
       " 'slovenia',\n",
       " 'from',\n",
       " 'croatia',\n",
       " ',',\n",
       " 'with',\n",
       " 'many',\n",
       " 'thousands',\n",
       " 'more',\n",
       " 'on',\n",
       " 'the',\n",
       " 'way',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'slovenian\",\n",
       " 'police',\n",
       " 'on',\n",
       " 'horseback',\n",
       " 'and',\n",
       " 'in',\n",
       " 'riot',\n",
       " 'gear',\n",
       " 'surrounded',\n",
       " 'hundreds',\n",
       " 'of',\n",
       " 'newcomers',\n",
       " 'in',\n",
       " 'a',\n",
       " 'muddy',\n",
       " 'field',\n",
       " 'near',\n",
       " 'the',\n",
       " 'border',\n",
       " 'village',\n",
       " 'of',\n",
       " 'rigonce',\n",
       " 'on',\n",
       " 'tuesday',\n",
       " ',',\n",
       " 'herding',\n",
       " 'them',\n",
       " 'on',\n",
       " 'a',\n",
       " '9-mile',\n",
       " 'trek',\n",
       " 'to',\n",
       " 'the',\n",
       " 'nearest',\n",
       " 'overcrowded',\n",
       " 'reception',\n",
       " 'area',\n",
       " '.',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'refugees',\n",
       " 'wrapped',\n",
       " 'themselves',\n",
       " 'in',\n",
       " 'blankets',\n",
       " 'to',\n",
       " 'ward',\n",
       " 'off',\n",
       " 'the',\n",
       " 'cold',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'police\",\n",
       " ',',\n",
       " 'above',\n",
       " ',',\n",
       " 'watched',\n",
       " 'hundreds',\n",
       " 'of',\n",
       " 'migrants',\n",
       " 'after',\n",
       " 'they',\n",
       " 'crossed',\n",
       " 'from',\n",
       " 'croatia',\n",
       " 'to',\n",
       " 'brezice',\n",
       " ',',\n",
       " 'slovenia',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'slovenia\",\n",
       " 'says',\n",
       " 'it',\n",
       " 'can',\n",
       " 'handle',\n",
       " 'only',\n",
       " '2,500',\n",
       " 'migrants',\n",
       " 'a',\n",
       " 'day',\n",
       " '.',\n",
       " 'on',\n",
       " 'tuesday',\n",
       " ',',\n",
       " '8,000',\n",
       " 'arrived',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'migrants\",\n",
       " ',',\n",
       " 'above',\n",
       " ',',\n",
       " 'attempted',\n",
       " 'to',\n",
       " 'break',\n",
       " 'through',\n",
       " 'a',\n",
       " 'cordon',\n",
       " 'in',\n",
       " 'a',\n",
       " 'makeshift',\n",
       " 'camp',\n",
       " 'near',\n",
       " 'the',\n",
       " 'austrian-slovenian',\n",
       " 'border',\n",
       " 'in',\n",
       " 'sentilj',\n",
       " ',',\n",
       " 'slovenia',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'wrapped\",\n",
       " 'in',\n",
       " 'blankets',\n",
       " 'or',\n",
       " 'standing',\n",
       " 'around',\n",
       " 'fires',\n",
       " 'to',\n",
       " 'warm',\n",
       " 'up',\n",
       " 'in',\n",
       " 'biting',\n",
       " 'wind',\n",
       " 'and',\n",
       " 'cold',\n",
       " ',',\n",
       " 'hundreds',\n",
       " 'were',\n",
       " 'waiting',\n",
       " 'to',\n",
       " 'cross',\n",
       " 'from',\n",
       " 'serbia',\n",
       " 'to',\n",
       " 'croatia',\n",
       " 'and',\n",
       " 'continue',\n",
       " 'their',\n",
       " 'journey',\n",
       " 'toward',\n",
       " 'western',\n",
       " 'europe',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " '``',\n",
       " 'slovenia',\n",
       " \"'s\",\n",
       " 'government',\n",
       " 'is',\n",
       " 'pleading',\n",
       " 'for',\n",
       " 'help',\n",
       " 'from',\n",
       " 'its',\n",
       " 'european',\n",
       " 'neighbors',\n",
       " 'as',\n",
       " 'it',\n",
       " 'struggles',\n",
       " 'to',\n",
       " 'cope',\n",
       " 'with',\n",
       " 'the',\n",
       " 'influx',\n",
       " '.',\n",
       " '``',\n",
       " ',',\n",
       " \"'more\",\n",
       " 'migrants',\n",
       " 'disembarked',\n",
       " 'from',\n",
       " 'a',\n",
       " 'train',\n",
       " ',',\n",
       " 'above',\n",
       " ',',\n",
       " 'on',\n",
       " 'their',\n",
       " 'way',\n",
       " 'to',\n",
       " 'the',\n",
       " 'croatian-slovenian',\n",
       " 'border',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'tensions\",\n",
       " 'have',\n",
       " 'built',\n",
       " 'along',\n",
       " 'the',\n",
       " 'migrant',\n",
       " 'trail',\n",
       " 'after',\n",
       " 'hungary',\n",
       " 'used',\n",
       " 'razor',\n",
       " 'wire',\n",
       " 'to',\n",
       " 'close',\n",
       " 'off',\n",
       " 'its',\n",
       " 'borders',\n",
       " 'with',\n",
       " 'serbia',\n",
       " 'and',\n",
       " 'croatia',\n",
       " 'to',\n",
       " 'the',\n",
       " 'migrants\\\\xa0',\n",
       " '--',\n",
       " 'pushing',\n",
       " 'the',\n",
       " 'flow',\n",
       " 'west',\n",
       " 'into',\n",
       " 'slovenia',\n",
       " ',',\n",
       " 'which',\n",
       " 'in',\n",
       " 'turn',\n",
       " 'has',\n",
       " 'also',\n",
       " 'sought',\n",
       " 'to',\n",
       " 'limit',\n",
       " 'arrivals',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'slovenia\",\n",
       " 'says',\n",
       " 'croatia',\n",
       " 'is',\n",
       " 'sending',\n",
       " 'thousands',\n",
       " 'of',\n",
       " 'migrants',\n",
       " 'toward',\n",
       " 'its',\n",
       " 'borders',\n",
       " '“',\n",
       " 'without',\n",
       " 'control',\n",
       " ',',\n",
       " '”',\n",
       " 'ignoring',\n",
       " 'requests',\n",
       " 'to',\n",
       " 'contain',\n",
       " 'the',\n",
       " 'surge',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'migrants\",\n",
       " ',',\n",
       " 'above',\n",
       " ',',\n",
       " 'walked',\n",
       " 'towards',\n",
       " 'a',\n",
       " 'reception',\n",
       " 'facility',\n",
       " 'in',\n",
       " 'dobovna',\n",
       " ',',\n",
       " 'slovenia',\n",
       " ',',\n",
       " 'after',\n",
       " 'crossing',\n",
       " 'from',\n",
       " 'croatia.\\\\xa0',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'slovenian\",\n",
       " 'police',\n",
       " 'used',\n",
       " 'pepper',\n",
       " 'spray',\n",
       " 'to',\n",
       " 'try',\n",
       " 'to',\n",
       " 'prevent',\n",
       " 'some',\n",
       " '200',\n",
       " 'migrants',\n",
       " 'from',\n",
       " 'jumping',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'a',\n",
       " 'long',\n",
       " 'line',\n",
       " 'of',\n",
       " 'people',\n",
       " 'waiting',\n",
       " 'to',\n",
       " 'enter',\n",
       " 'austria',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'took',\n",
       " 'a',\n",
       " 'barrier',\n",
       " 'set',\n",
       " 'up',\n",
       " 'by',\n",
       " 'austrian',\n",
       " 'police',\n",
       " 'to',\n",
       " 'stop',\n",
       " 'them',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'migrants\",\n",
       " ',',\n",
       " 'above',\n",
       " ',',\n",
       " 'broke',\n",
       " 'through',\n",
       " 'a',\n",
       " 'cordon',\n",
       " 'in',\n",
       " 'a',\n",
       " 'makeshift',\n",
       " 'camp',\n",
       " 'near',\n",
       " 'the',\n",
       " 'austrian',\n",
       " 'border',\n",
       " 'in',\n",
       " 'sentilj',\n",
       " ',',\n",
       " 'slovenia',\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'then\",\n",
       " 'they',\n",
       " 'ran',\n",
       " 'down',\n",
       " 'a',\n",
       " 'street',\n",
       " 'toward',\n",
       " 'the',\n",
       " 'border',\n",
       " '.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news[\"Content\"].iloc[3880]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace rare words with ```<unk>``` \n",
    "\n",
    "Keeping only 40k most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ```<eos>``` to the end of content list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating punctuation from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sup_punct(list):\n",
    "    \"\"\"\n",
    "    seperating punctuation from words\n",
    "    *args: list of strings\n",
    "    return: list of strings\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"points\": [],\n",
    "        \"quotes\" []\n",
    "    }\n",
    "    \n",
    "    for idx,item in enumerate(list):\n",
    "        foud_dot = re.search(r\"\", item)\n",
    "        found_quote = re.search(r\"\", item)\n",
    "        if found_dot:\n",
    "            \n",
    "        if found_quote:\n",
    "            \n",
    "    \n",
    "    if hochkomma:\n",
    "        list = \n",
    "    elif punkt:\n",
    "        \n",
    "    else:\n",
    "        return list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
