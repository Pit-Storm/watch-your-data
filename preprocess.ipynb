{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_pickle(\"data/data_raw.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:  19076\n",
      "Rows left: 185059\n"
     ]
    }
   ],
   "source": [
    "before = df_news.shape[0]\n",
    "\n",
    "to_drop = [\"\",\"[]\"]\n",
    "for col in df_news.columns:\n",
    "    if col != \"ID\":\n",
    "        for item in to_drop:\n",
    "            df_news = df_news[df_news[col] != item]\n",
    "        df_news = df_news[df_news[col].notnull()]\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing interpunction misstakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_interpunction(item):\n",
    "    \"\"\"\n",
    "    Inserting space when missing after sentence ending.\n",
    "    *args: item string\n",
    "    return: fixed item string\n",
    "    \"\"\"\n",
    "    match = re.search(r\"[\\w\\d][\\.\\!\\?][\\w\\d]\",item)\n",
    "    if match:\n",
    "        item = item[:match.start()+2] + str(\" \") + item[match.end()-1:]\n",
    "        return fix_interpunction(item)\n",
    "    else:\n",
    "        return item\n",
    "\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(fix_interpunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping only first ten sentences of \"Content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_10(row):\n",
    "    \"\"\"Only keep first 10 sentences of Content\n",
    "    *args: pandas row object\n",
    "    return: string\n",
    "    \"\"\"\n",
    "    return reduce(lambda i,j: i + j, re.split(r'([\\.\\!\\?]\\s)', row ,10)[:20])\n",
    "\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(keep_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows where Headline occurs in Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:    840\n",
      "Rows left: 184219\n"
     ]
    }
   ],
   "source": [
    "def headline_in_content(row):\n",
    "    is_in = row[\"Content\"].find(row[\"Headline\"])\n",
    "    if is_in == -1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "before = df_news.shape[0]\n",
    "\n",
    "df_news = df_news[df_news.apply(headline_in_content, axis=1) == False]\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "# Only when first using nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news[\"Headline\"] = df_news[\"Headline\"].str.lower()\n",
    "df_news[\"Content\"] = df_news[\"Content\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline done. Took  0 minutes.\n",
      "Content Done. Took  5 minutes.\n"
     ]
    }
   ],
   "source": [
    "tokenize_start = time.time()\n",
    "df_news[\"Headline\"] = df_news[\"Headline\"].apply(nltk.word_tokenize)\n",
    "tokenize_end = time.time()\n",
    "print(\"Headline done. Took {0:2.0f} minutes.\".format((tokenize_end - tokenize_start)/60))\n",
    "\n",
    "tokenize_start = time.time()\n",
    "df_news[\"Content\"] = df_news[\"Content\"].apply(nltk.word_tokenize)\n",
    "tokenize_end = time.time()\n",
    "print(\"Content Done. Took {0:2.0f} minutes.\".format((tokenize_end - tokenize_start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Headlines > 25 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped:    649\n",
      "Rows left: 183570\n"
     ]
    }
   ],
   "source": [
    "def headline_gt_25(item):\n",
    "    \"\"\"\n",
    "    rows with more than 25 tokens in headline\n",
    "    \n",
    "    *args: row\n",
    "    return: row\n",
    "    \"\"\"\n",
    "    if len(item) > 25: return True\n",
    "    else: return False\n",
    "\n",
    "before = df_news.shape[0]\n",
    "\n",
    "df_news = df_news[df_news[\"Headline\"].apply(headline_gt_25) == False]\n",
    "\n",
    "after = df_news.shape[0]\n",
    "print(\"Rows dropped: {0:6d}\".format(before - after))\n",
    "print(\"Rows left: {0:6d}\".format(after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_news.to_pickle(\"data/data_preprocessed.pickle\")\n",
    "\n",
    "#df_news = pd.read_pickle(\"data/data_preprocessed.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortening Content down to last sentence having 50th token\n",
    "\n",
    "## TODO\n",
    "producing None values. ID = 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_content(item):\n",
    "    \"\"\"\n",
    "    Shortening content down to <= 50 tokens be aware of sentences.\n",
    "    \n",
    "    *args: content item list\n",
    "    return: shortend content item list\n",
    "    \"\"\"\n",
    "    if len(item) > 50:\n",
    "        endings = []\n",
    "        for i in range(len(item)):\n",
    "            if item[i] == ('.' or '!' or '?'):\n",
    "                endings.append(i)\n",
    "            if endings:\n",
    "                if endings[-1] > 49:\n",
    "                    return item[:endings[-1]+1]\n",
    "    else:\n",
    "        return item\n",
    "\n",
    "#df_news[\"Content\"] = df_news[\"Content\"].apply(shorten_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                        104\n",
       "Headline    [uber, is, recruiting, 50,000, veterans, as, d...\n",
       "Content                                                  None\n",
       "Name: 92, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news[df_news[\"Content\"].isna()].iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
